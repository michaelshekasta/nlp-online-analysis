{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "s1 = 'דיכאון'\n",
    "s2 = 'דכאון'\n",
    "nltk.edit_distance(s1, s2, transpositions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "typo_word= 'בטיחון'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of stop words and adding custom stopwords\n",
    "import codecs\n",
    "with codecs.open('bgulex.utf8.hr', 'r', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_heb_dict = set()\n",
    "for line in lines:\n",
    "    word = line.split(':')[0].split(' ')[0].strip().replace(' DEF','')\n",
    "    if len(word) > 0:\n",
    "        words_in_heb_dict.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_words_in_keyboard = {'א' : 'רכעיט',\n",
    "'ב' : 'סדגכה',\n",
    "'ג' : 'רכהבסד',\n",
    "'ד' : 'גבסזש',\n",
    "'ה' : 'בגכענ',\n",
    "'ו' : 'םךלחו',\n",
    "'ז' : 'סדש',\n",
    "'ח' : 'יטוןלתצמ',\n",
    "'ט' : 'אעחו',\n",
    "'י' : 'אטוחצמנע',\n",
    "'כ' : 'קראענהבג',\n",
    "'ל' : 'חוןםךצ',\n",
    "'מ' : 'ניחצ',\n",
    "'נ' : 'מיעה',\n",
    "'ס' : 'זשדגב',\n",
    "'ע' : 'כראטינה',\n",
    "'פ' : 'םלך',\n",
    "'צ' : 'מחלת',\n",
    "'ק' : 'רכגד',\n",
    "'ר' : 'קגכעא',\n",
    "'ש' : 'דסז',\n",
    "'ת' : 'צלךץ',\n",
    "'ם' : 'ןלךףפ',\n",
    "'ן' : 'וחלךם',\n",
    "'ץ' : 'ףךת',\n",
    "'ף' : 'פםךץ',\n",
    "'ך' : 'ףפםןלת'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words_that_has_nearest_letters_in_keyboard(nearest_words_in_keyboard,word,number_letters=1):\n",
    "    closest_words = list()\n",
    "    for letter_index in range(len(word)):\n",
    "        letter = word[letter_index]\n",
    "        for near_letters in nearest_words_in_keyboard[letter]:\n",
    "            new_word = str(word[:letter_index] + near_letters +word[letter_index+1:])\n",
    "            closest_words.append(new_word)\n",
    "            if number_letters > 1:\n",
    "                for new_word_ in fix_by_nearest_letters_in_keyboard(nearest_words_in_keyboard,new_word,number_letters-1):\n",
    "                    closest_words.append(new_word_)\n",
    "    for close_word in set(closest_words):\n",
    "        yield close_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutations(string,number_swaps=1,location=0):\n",
    "    # everything to the right of step has not been swapped yet\n",
    "    prem_words = []\n",
    "    for i in range(location,len(string)-1):\n",
    "\n",
    "        # copy the string (store as array)\n",
    "        string_copy = [character for character in string]\n",
    "\n",
    "        # swap the current index with the step\n",
    "        string_copy[i], string_copy[i+1] = string_copy[i+1], string_copy[i]\n",
    "\n",
    "        prem_words += [''.join(string_copy)]\n",
    "        if number_swaps > 1:\n",
    "            for i in permutations(string_copy,number_swaps-1,location+3):\n",
    "                prem_words += [i]\n",
    "    for i in set(prem_words):\n",
    "        yield i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transpory_words(word,heb_dict):\n",
    "    perms = [''.join(p) for p in permutations(word)]\n",
    "    for perm in perms:\n",
    "        if perm in heb_dict:\n",
    "            yield perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ביטחון\n"
     ]
    }
   ],
   "source": [
    "for i in generate_transpory_words(typo_word,words_in_heb_dict):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_words(heb_dict,distance_word):\n",
    "    distance = -1\n",
    "    closest_words = list()\n",
    "    for word in heb_dict:\n",
    "        curr_distance = nltk.edit_distance(word, distance_word, transpositions=True)\n",
    "        if distance == curr_distance:\n",
    "            closest_words += [word]\n",
    "        if distance > curr_distance or distance == -1:\n",
    "            distance = curr_distance\n",
    "            closest_words = [word]\n",
    "    closest_words = sorted(closest_words, key=len)\n",
    "    return closest_words, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_typo_hebrew(word, start_index=0):\n",
    "    common_words = list()\n",
    "    for letter_index in range(start_index, len(word)):\n",
    "        letter = word[letter_index]\n",
    "        near_letters = [letter]\n",
    "        letter = word[letter_index]\n",
    "        if letter == 'כ':\n",
    "            near_letters = ['ח','ק']\n",
    "        if letter == 'ח':\n",
    "            near_letters = ['ק','כ']\n",
    "        if letter == 'ק':\n",
    "            near_letters = ['ח','כ']\n",
    "        if letter == 'ש':\n",
    "            near_letters = ['ס']\n",
    "        if letter == 'ס':\n",
    "            near_letters = ['ש']\n",
    "        if letter == 'ו':\n",
    "            near_letters = ['ב']\n",
    "        if letter == 'ב':\n",
    "            near_letters = ['ו']\n",
    "        if letter == 'א':\n",
    "            near_letters = ['ע','ה']\n",
    "        if letter == 'ך':\n",
    "            near_letters = ['ח']\n",
    "        if letter == 'ה':\n",
    "            near_letters = ['ע','א']\n",
    "        if letter == 'ע':\n",
    "            near_letters = ['א','ה']\n",
    "        if letter == 'ט':\n",
    "            near_letters = ['ת']\n",
    "        if letter == 'ת':\n",
    "            near_letters = ['צ']\n",
    "        if near_letters[0] != letter:\n",
    "            for near_letter in near_letters:\n",
    "                new_word = str(word[:letter_index] + near_letter +word[letter_index+1:])\n",
    "                common_words += [new_word]\n",
    "                common_words += common_typo_hebrew(new_word,letter_index+1)\n",
    "    for common_word in common_words:\n",
    "        yield common_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 281 ms, total: 28.8 s\n",
      "Wall time: 31.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['בטיחו', 'בטיחן', 'בטחון', 'בטיחות', 'ביטחון', 'בטיחכן', 'בטיחותן'], 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time find_closest_words(words_in_heb_dict, typo_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojies(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return str(emoji_pattern.sub(r'', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_words = ['מתשמש','היתקבל','אזרחןת','מדריח','וקמנדו','היתגייס','מוצאש','אפסדים','גמילים','פסכיאטר','אישתתף','קיריה','תאבחון','תחיילתם','לירפא','משיהו','הל''צ','אווירנאוטיקה','מעונין','פסיכיטאר','מישוא','ויד','דיגטלי','ריאיונות','צה\\'ל','פסיכאטריות','יפואלרגני']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ויד ------> יוד\n",
      "פסיכיטאר ------> פסיכיאטר\n",
      "מעונין ------> מעוינן\n",
      "מתשמש ------> תמשמש\n",
      "מתשמש ------> משתמש\n",
      "משיהו ------> מישהו\n",
      "אזרחןת ------> אזרחתן\n",
      "הלצ ------> הצל\n",
      "קיריה ------> קרייה\n",
      "קיריה ------> יקריה\n",
      "וקמנדו ------> קומנדו\n",
      "גמילים ------> גימלים\n"
     ]
    }
   ],
   "source": [
    "for word in set(problem_words):\n",
    "    for i in generate_transpory_words(word,words_in_heb_dict):\n",
    "        print(f'{word} ------> {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ויד ------> ליד\n",
      "ויד ------> ועד\n",
      "מעונין ------> מעונים\n",
      "מעונין ------> מעוננן\n",
      "מעונין ------> מעויין\n",
      "משיהו ------> משיבו\n",
      "משיהו ------> משיכו\n",
      "משיהו ------> משינו\n",
      "משיהו ------> משחהו\n",
      "משיהו ------> משנהו\n",
      "משיהו ------> משיגו\n",
      "מישוא ------> מישור\n",
      "אזרחןת ------> אזרחות\n",
      "הלצ ------> הלל\n",
      "הלצ ------> הלח\n",
      "היתקבל ------> המתקבל\n",
      "קיריה ------> קוריה\n",
      "קיריה ------> כיריה\n",
      "קיריה ------> דיריה\n",
      "קיריה ------> גיריה\n",
      "קיריה ------> קיאיה\n",
      "קיריה ------> ריריה\n",
      "קיריה ------> קמריה\n",
      "קיריה ------> קצריה\n",
      "קיריה ------> קטריה\n",
      "גמילים ------> גמולים\n",
      "גמילים ------> המילים\n",
      "היתגייס ------> המתגייס\n",
      "מדריח ------> מבריח\n",
      "מדריח ------> מסריח\n"
     ]
    }
   ],
   "source": [
    "for word in set(problem_words):\n",
    "    if len(word) > 1:\n",
    "        typo_word = remove_emojies(word)\n",
    "        #print(typo_word)\n",
    "        try:\n",
    "            for i in generate_words_that_has_nearest_letters_in_keyboard(nearest_words_in_keyboard,typo_word):\n",
    "                if i in words_in_heb_dict:\n",
    "                    print(f'{typo_word} ------> {i}')\n",
    "        except:\n",
    "            #print(typo_word)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ויד ------> ביד\n",
      "משיהו ------> מסיעו\n",
      "משיהו ------> משיאו\n",
      "מישוא ------> מישבה\n",
      "אפסדים ------> הפסדים\n",
      "היתקבל ------> איתחול\n",
      "קיריה ------> כיריה\n"
     ]
    }
   ],
   "source": [
    "for word in set(problem_words):\n",
    "    for i in common_typo_hebrew(word):\n",
    "        if i in words_in_heb_dict:\n",
    "            print(f'{word} ------> {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'thread'\n",
    "field_name = 'title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f'{file_type}_with_yap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the problematic word is מתשמש\n",
      "['לא יכול להיכנס למתשמש של מתגייסים - FXP']\n",
      "the problematic word is היתקבל\n",
      "['עם ההיתי בכלא צבאי על סמים אני יוכל להיתקבל באזרחות לעבודה עם - FXP']\n",
      "the problematic word is אזרחןת\n",
      "['כדורים מפסיכאטר יכתב לי באזרחןת - FXP']\n",
      "the problematic word is מדריח\n",
      "['דרישות במיון למדריח כושר גופני - FXP']\n",
      "the problematic word is וקמנדו\n",
      "['סיירת שיריון מול חטיבת הוקמנדו - FXP']\n",
      "the problematic word is היתגייס\n",
      "['כל האנשים ששלחו טופס 55 לקרבי וצריכים להיתגייס בנובמבר-דצמבר - FXP', 'כל האנשים ששלחו טופס 55 לקרבי וצריכים להיתגייס בנובמבר-דצמבר - FXP', 'לכל אלה שעומדים להיתגייס בחודש הקרוב או בחודשיים הקרובים - FXP', 'מה אתם מעדיפים להיתגייס או לעשות שנת שירות - FXP', 'מחר יש לי שיחה עם קצין מיון גברים לגיוס... ולא בא לי להיתגייס - FXP', 'מסוכן להיתגייס לשבס? - FXP', 'רוצה להיתגייס לתותחנים - FXP']\n",
      "the problematic word is מוצאש\n",
      "['ביקור רופא בראשון לציון פתוח עד 1 במוצאש בטוח נכון ? - FXP']\n",
      "the problematic word is אפסדים\n",
      "['צהל צריך כאלה לאפסדים - FXP']\n",
      "the problematic word is גמילים\n",
      "['איך לקבל הרבה גמילים בשביל לעבור בסיס ? - FXP']\n",
      "the problematic word is פסכיאטר\n",
      "['דחוף - אפשר בפרטי - המלצה לפסכיאטר פרטי , תודה - FXP', 'פסכיאטר יכול לשקר? - FXP']\n",
      "the problematic word is אישתתף\n",
      "['מישאו מיפה אישתתף בצוק איתן? - FXP']\n",
      "the problematic word is קיריה\n",
      "['ראיון בקיריה - FXP']\n",
      "the problematic word is תאבחון\n",
      "['באסהההההההההההההה לא קיבלו לי תאבחון?!?!? - FXP']\n",
      "the problematic word is תחיילתם\n",
      "['עתודאים, מתי התחיילתם? בזמן הלימודים או לפני? - FXP']\n",
      "the problematic word is לירפא\n",
      "[\"טופס זימון לירפא' א - FXP\", 'מבחנים ממוחשבים לירפא (מנחית סער קדמי) - FXP', 'שלום ישלי מיון לירפא ואני ממש רוצה להתקבל כדאי לקנות את הערכה של מכון נועם - FXP', 'בקשר לירפא א חלק 2 / ירפא ב - FXP', 'תעודת זהות לירפא 112 - FXP', 'מתי להגיע לירפא ב מחר? כתוב להגיע ב11:00 אבל רוצה לצאת משם כמה - FXP', 'שאלה - בקשר לירפא א חלק שני - FXP']\n",
      "the problematic word is משיהו\n",
      "['משיהו שמבין בהתש חייב עזרה!! - FXP']\n",
      "the problematic word is הלצ\n",
      "['רק הנדסה קרבית נמצאים בבהלצ? - FXP', 'טירונות 02 בבהלצ היא בחדרים או אוהלים? - FXP', 'איך האוכל בבהלצ - FXP', 'איך התש בבהלצ? - FXP']\n",
      "the problematic word is אווירנאוטיקה\n",
      "['התייעצות לגבי עתודה באווירנאוטיקה וסילון - FXP']\n",
      "the problematic word is מעונין\n",
      "['לא מעונין בתפקיד במודיעין - FXP', 'שלום רב הבן שלי כרגע בטירונות כפיר .כבר חצי שנה א מעונין להמשיך - FXP']\n",
      "the problematic word is פסיכיטאר\n",
      "['הכדורים של הפסיכיטאר יעזרו לי - FXP']\n",
      "the problematic word is מישוא\n",
      "['אם יש למישוא רישיון לאקדח הוא יכול אקדח כזה? - FXP']\n",
      "the problematic word is ויד\n",
      "['האם אפשר לבטל יג ויד ולא לקבל תפקיד בחיל החימוש - FXP', 'מה אתם חושבים על הווידוים שמפרסמים על יחידת מיטב בקונפשיינס? - FXP', 'אם פלמחים זה חצי שעה מהבית שלי, ואני מפיקת וידאו בגף חופ״ה, אפשרי  יומיות? - FXP', 'נגיד הלכתי למיון כולשהו וידוע שעד שבוע אחרי המיון אפשר לחתום - FXP', 'וויד - FXP', \"רופא בצה''ל תקף חייל שבא לקבל טיפול - וידיאו בלינק - FXP\", 'לאן מאפסים מאג? מה הווידוי איפוס ומה השווי קליק שלו? - FXP', 'איזה תפקידים לבנים יש בצבא שהם לא לחימה וידע במחשבים בבסיס סגור - FXP', 'רכזת חינוך וידיעת הארץ (משקית חינוך) - FXP', 'קורס נהגי דויד - FXP', 'בלתי פגיע - הסיפור המטורף של דויד גוגינס - FXP', 'תקרית בגבול עזה:לוחמי צה\"ל חיסלו מחבלים המצוידים ברובים, רימוני יד ומטול RP - FXP', 'מישהו שהתמיין למוידעין במחזור הזה ? - FXP', 'אחיינית שלי נימצאת ברמת דויד אני חולה מאוד ואין לי אף אחד היא - FXP']\n",
      "the problematic word is דיגטלי\n",
      "['קורס מפעילת דיגטלי מבצעי נייד - FXP']\n",
      "the problematic word is ריאיונות\n",
      "['יש פה מישהו שאמור לקבל זימון לשבוע ריאיונות ועוד לא קיבל? - FXP', 'מישהו יודע מה קורה עם השבוע ריאיונות - FXP', 'תכונות בריאיונות - FXP']\n",
      "the problematic word is צה'ל\n",
      "[\"על ביבי נתניהו וצה'ל - FXP\", \"פרסומת לצה'ל - FXP\", \"על נשק וצה'ל - FXP\", \"שאלה מגוחכת על צה'ל ופורנו - FXP\", \"הילד מלוד ,שהתמכר לסמים ,התגייס לצה'ל וכבש את ליבו של נשיא המדינה!!!! - FXP\"]\n",
      "the problematic word is פסיכאטריות\n",
      "['תרופות פסיכאטריות בצבא - FXP']\n",
      "the problematic word is יפואלרגני\n",
      "['חדר היפואלרגני - FXP', 'חדר היפואלרגני בתותחנים - FXP', 'מהו חדר היפואלרגני ? - FXP', 'חדר היפואלרגני. - FXP']\n"
     ]
    }
   ],
   "source": [
    "for problematic_word in problem_words:\n",
    "    print(f'the problematic word is {problematic_word}')\n",
    "    print(list(df.loc[df[f'{field_name}'].str.contains(problematic_word)][f'{field_name}']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
